{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'/datasets/home/home-02/60/960/kshi/image2story')\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from skip_thoughts.data_loader import DataLoader\n",
    "from skip_thoughts.model import UniSkip\n",
    "from skip_thoughts.config import *\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pathlib\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Root = '/datasets/home/home-02/60/960/kshi/image2story'\n",
    "data_path = os.path.join(Root,'data/books_large_p1.txt')\n",
    "# data_dummy_path = os.path.join(Root,'data/dummy_corpus.txt')\n",
    "logs_path = os.path.join(Root,'logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DataLoader(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save loss in files for futher usage.\n",
    "loss_path = Root + '/logs/losses/{}/'.format(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "loss_pathlib = pathlib.Path(loss_path)\n",
    "if not loss_pathlib.exists():\n",
    "    pathlib.Path(loss_pathlib).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "lr = 1e-4\n",
    "model = UniSkip()\n",
    "model = model.to(computing_device)\n",
    "optimizer = optim.Adam(model.parameters(),lr =lr)\n",
    "# load weights\n",
    "load_pretrained = True\n",
    "if load_pretrained: \n",
    "    MODEL_PATH = os.path.join(logs_path, 'skip-best-2400')\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_trail = []\n",
    "last_best_loss = None\n",
    "current_time = datetime.utcnow()\n",
    "\n",
    "def debug(i, loss, prev, nex, prev_pred, next_pred):\n",
    "    global loss_trail\n",
    "    global last_best_loss\n",
    "    global current_time\n",
    "\n",
    "    this_loss = loss.data[0]\n",
    "    loss_trail.append(this_loss)\n",
    "    loss_trail = loss_trail[-20:]\n",
    "    new_current_time = datetime.utcnow()\n",
    "    time_elapsed = str(new_current_time - current_time)\n",
    "    current_time = new_current_time\n",
    "    print(\"Iteration {}: time = {} last_best_loss = {}, this_loss = {}\".format(\n",
    "              i, time_elapsed, last_best_loss, this_loss))\n",
    "    \n",
    "    print(\"prev = {}\\nnext = {}\\npred_prev = {}\\npred_next = {}\".format(\n",
    "        d.convert_indices_to_sentences(prev),\n",
    "        d.convert_indices_to_sentences(nex),\n",
    "        d.convert_indices_to_sentences(prev_pred),\n",
    "        d.convert_indices_to_sentences(next_pred),\n",
    "    ))\n",
    "    #Save loss in a txt file.\n",
    "    with open(os.path.join(loss_path, \"training.txt\"), \"a\") as f:\n",
    "        f.write(str(this_loss.item()) +\"\\n\")\n",
    "        \n",
    "    try:\n",
    "        trail_loss = sum(loss_trail)/len(loss_trail)\n",
    "        if last_best_loss is None or last_best_loss > trail_loss:\n",
    "            print(\"Loss improved from {} to {}\".format(last_best_loss, trail_loss))\n",
    "            \n",
    "            save_loc = logs_path +'/skip-best-2400'.format(lr, VOCAB_SIZE)\n",
    "            print(\"saving model at {}\".format(save_loc))\n",
    "            torch.save(model.state_dict(), save_loc)\n",
    "            \n",
    "            last_best_loss = trail_loss\n",
    "    except Exception as e:\n",
    "       print(\"Couldn't save model because {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "# Roughly 312500 iterations one epoch if batch size is 128.\n",
    "for i in range(0, 100000):\n",
    "    optimizer.zero_grad()\n",
    "    sentences, lengths = d.fetch_batch(128,i)\n",
    "    loss, prev, nex, prev_pred, next_pred  = model(sentences, lengths)\n",
    "    if i % 20 == 0:\n",
    "        debug(i, loss, prev, nex, prev_pred, next_pred)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(model.parameters(), 10)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
